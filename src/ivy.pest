// basic tokenization
char = { ASCII_ALPHANUMERIC | "_" | ":" | "." }
WHITESPACE = _{ " " | "\t" | NEWLINE }
// ident = @{ ASCII_ALPHA ~ (char* ~ ("." ~ char*)*) }
ident = @{ char+ }

// the top-level rule
file = { SOI ~ step_def* ~ EOI }

step_def = { ident ~ "=" ~  action }
action = { "action" ~ ("(" ~ ident ~ ")")? ~ rule_block }
rule_block_or_step = { rule_block | rule_step }
rule_block = {
  // an empty rule block
  "{" ~ "}"
  | "{" ~ rule_block_or_step ~
    (";" ~ rule_block_or_step)* ~ "}"
}

rule_step = { assign_rule | assume_rule | assert_rule | if_rule }

assign_rule = { expr ~ ":=" ~ expr }
assume_rule = {  "assume" ~ expr }
assert_rule = {  "assert" ~ expr }
if_rule = {
  "if" ~ expr ~ rule_block_or_step ~
  ("else" ~ rule_block_or_step)?
}

expr = { prefix* ~ term ~ (infix ~ prefix* ~ term)* }

// the infix/prefix operators
infix = _{ and | implies }
and = { "&" }
implies = { "->" }
prefix = _{ not }
not = { "~" }

// some other expression constructs
call_expr = { ident ~ "(" ~ ident ~ ")" }
forall_expr = { "forall" ~ ident  ~ "." ~ expr }
some_expr = { "some" ~ ident  ~ "." ~ expr }
base_expr =  { call_expr | forall_expr | some_expr | ident }
term = _{ base_expr | "(" ~ expr ~ ")" }
